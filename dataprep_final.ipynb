{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84175,"databundleVersionId":9816926,"sourceType":"competition"},{"sourceId":10330438,"sourceType":"datasetVersion","datasetId":6396478},{"sourceId":10352178,"sourceType":"datasetVersion","datasetId":6410439}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U kaleido","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Rush Play Data\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 500)\npd.options.mode.chained_assignment = None\n\nimport matplotlib.pyplot as plt\n\ndef calc_run_success(row):\n    yards_to_go = row['yardsToGo']\n    yards_gained = row['yardsGained']\n    if yards_gained<=0:\n        return 0\n    elif row['down'] == 1:\n        return 1 if (yards_gained / yards_to_go) >=.4 else 0\n    elif row['down'] == 2:\n        return 1 if (yards_gained / yards_to_go) >=.6 else 0 \n    else:\n        return 1 if yards_to_go<=yards_gained else 0\n\nplay_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/plays.csv')\ngames_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/games.csv')\n\nplay_df = play_df.merge(games_df[['gameId', 'week']], how='left', on=['gameId'])\n\nplay_cols = [\n    'gameId',\n    'playId',\n    'week',\n    'playDescription',\n    'possessionTeam',\n    'quarter',\n    'down',\n    'yardsToGo',\n    'absoluteYardlineNumber',\n    'rushLocationType',\n    'yardsGained',\n    'pff_runConceptPrimary',\n    'pff_runConceptSecondary'\n]\n\nrush_df = (\n    play_df[\n    (play_df.playNullifiedByPenalty == 'N')&\n    (play_df.isDropback == False)&\n    (play_df.qbKneel == 0)&\n    (pd.isnull(play_df.penaltyYards))]\n)[play_cols]\nrush_df['runSuccess'] = rush_df.apply(calc_run_success, axis=1)\nrush_df = rush_df.sort_values(by=['gameId', 'playId']).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_winner(row):\n    return row['homeTeamAbbr'] if row['homeFinalScore'] > row['visitorFinalScore'] else row['visitorTeamAbbr']\n\ngames_df['winner'] = games_df.apply(get_winner, axis=1)\n\npoint_dict = {}\nwin_dict = {}\nfor team in games_df.homeTeamAbbr.unique():\n    games_played_df = games_df[(games_df.homeTeamAbbr==team)|(games_df.visitorTeamAbbr==team)]\n    point_dict[team]=0\n    point_dict[team]+=games_df[games_df.homeTeamAbbr==team].homeFinalScore.sum()\n    point_dict[team]+=games_df[games_df.visitorTeamAbbr==team].visitorFinalScore.sum()\n    point_dict[team]/= len(games_played_df)\n    point_dict[team] = round(point_dict[team],1)\n\n    win_dict[team] = round(len(games_played_df[games_played_df.winner==team]) / len(games_played_df),2)\n    \nteam_points_df = pd.DataFrame({\n    'team':list(point_dict),\n    'ppg':list(point_dict.values())\n})\n\nteam_wins_df = pd.DataFrame({\n    'team':list(win_dict),\n    'win_%':list(win_dict.values())\n})\n# team_wins_df\n# plot_team_scatter('runSuccess')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\nimport numpy as np\n\ndef px_team_scatter(metric):\n    team_runsuccess_df = rush_df[~rush_df.playDescription.str.contains('FUMBLE|TOUCHDOWN')].groupby('possessionTeam')[[metric]].mean().reset_index().rename(columns={'possessionTeam':'team'})\n    team_df = team_runsuccess_df.merge(team_wins_df).merge(team_points_df)\n\n    # trend line\n    z = np.polyfit(team_df[metric], team_df['ppg'], 1)\n    p = np.poly1d(z)\n    team_df['trendline'] = p(team_df[metric])\n    \n    fig = px.scatter(\n        team_df, \n        x=metric, \n        y='ppg', \n        size='win_%', \n        hover_name='team',\n        size_max=15,\n        title='Team Performance by Run Success',\n        labels={\n            metric: 'Run Success %',\n            'ppg': 'Points Per Game'\n        }\n    )\n    \n    # trendline\n    fig.add_scatter(\n        x=team_df[metric], \n        y=team_df['trendline'], \n        mode='lines', \n        name=f'Trend Line', \n        line=dict(dash='dash', color='red')\n    )\n    \n    # Customize legend and layout\n    fig.update_traces(marker=dict(opacity=0.8, line=dict(width=1, color='black')))\n    fig.update_layout(\n        annotations=[\n            dict(\n                xref=\"paper\", \n                yref=\"paper\", \n                x=.05, \n                y=-0.2, \n                showarrow=False, \n                text=\"Bubble size represents Win Percentage\"\n            )\n        ]\n    )\n    fig.update_layout(showlegend=False)\n    fig.show()\n    # fig.write_image(\"/kaggle/working/Ex1_Team_Perf_by_RunSuccess.png\")\n    # fig.write_html(\"/kaggle/working/Ex1_Team_Perf_by_RunSuccess.html\")\npx_team_scatter('runSuccess')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tmp_df = rush_df[['gameId', 'playId', 'playDescription', 'down', 'yardsGained', 'runSuccess']].merge(play_df[['gameId', 'playId','expectedPointsAdded']])\nfiltered_df = (tmp_df[\n    (~tmp_df.playDescription.str.contains('FUMBLE|TOUCHDOWN'))&\n    (tmp_df.yardsGained.between(1,10))&\n    (tmp_df.down.isin([1,2]))\n    ])\nrun_success_by_yards_gained = (\n    filtered_df\n    .groupby(['yardsGained', 'runSuccess'])[['expectedPointsAdded']]\n    .mean()\n    .reset_index()\n    .pivot(index='yardsGained', columns='runSuccess', values='expectedPointsAdded')\n    .reset_index()\n)\nrun_success_by_yards_gained.columns = ['Yards Gained', 'Run Fail', 'Run Success']\n# filtered_df\n# run_success_by_yards_gained","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from plotly import graph_objects as go\n\nheader_values = list(run_success_by_yards_gained.columns)  # Column names\ncell_values = [round(run_success_by_yards_gained[col], 3).tolist() for col in run_success_by_yards_gained.columns]  # Data for each column\n\n# Create Plotly Table\nfig = go.Figure(data=[go.Table(\n    header=dict(values=header_values),\n    cells=dict(values=cell_values)\n)])\nfig.update_layout(\n    annotations=[\n    dict(\n        text=\"Excludes 3rd down, 4th down, and any play resulting in a turnover or touchdown\",\n        x=0.5,\n        y=-0.1,\n        xref=\"paper\",\n        yref=\"paper\",\n        showarrow=False,\n        font=dict(size=12)\n    )],\n    title=dict(\n        text=\"Avg. Expected Point Added by Rush Yard Gained\",\n        x=0.5,\n        xanchor='center',\n        yanchor='top'\n    )\n)\n# fig.write_image(\"/kaggle/working/Ex2_EPA_YPR_RunSuccess.png\")\n# fig.write_html(\"/kaggle/working/Ex2_EPA_YPR_RunSuccess.html\")\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Blocks df script\n\nimport geopandas as gpd\n\ndef o_math(num, val):\n    min_, max_ = num-val, num+val\n    if max_ > 360:\n        max_ = max_-360\n    if min_ < 0:\n        min_ = 360+min_\n    return min_, max_\n\ndef filter_orientation(df, col1, col2, val):\n    ''' copilot function.. double check output'''\n    filtered_df = df.copy()\n    for index, row in df.iterrows():\n        min_, max_ = o_math(row[col1], val)\n        if min_ <= max_:\n            if not (min_ <= row[col2] <= max_):\n                filtered_df.drop(index, inplace=True)\n        else:\n            if not (row[col2] >= min_ or row[col2] <= max_):\n                filtered_df.drop(index, inplace=True)\n    return filtered_df\n\ndef players_engaged_df(gdf, distance, poss_team):\n    play_direction = list(gdf.playDirection)[0]\n    # poss_team = list(gdf.possessionTeam)[0]\n    \n    if isinstance(gdf, pd.DataFrame):\n        gdf = gpd.GeoDataFrame(gdf, geometry=gpd.points_from_xy(gdf.x, gdf.y))\n        \n    gdf = gdf.copy()\n    gdf['geometry'] = gdf.geometry.buffer(distance)\n    gdf = gpd.sjoin(gdf, gdf, how='inner', predicate='intersects')\n    filter_poss = (gdf.club_right==poss_team) if play_direction == 'left' else (gdf.club_left==poss_team)\n    gdf = (\n        gdf[filter_poss& # only want one pair of the combo\n           (gdf.displayName_right!=gdf.displayName_left)&\n           (gdf.club_right!=gdf.club_left)&\n           (gdf.frameId_right == gdf.frameId_left)&\n           (gdf.displayName_left!='football')&\n           (gdf.displayName_right!='football')#&\n        ]).reset_index(drop=True)\n    gdf = filter_orientation(gdf, 'o_left', 'o_right', 270).reset_index(drop=True)\n    return gdf.rename(columns={'gameId_left':'gameId', 'playId_left':'playId'})\n\ndef get_blocks_from_engaged_df(df:pd.DataFrame, poss_team):\n    df = df.reset_index(drop=True)\n    # poss_team = df.possessionTeam_left.iloc[0]\n    # lazy way to determine who has ball:\n    if poss_team == df.club_right.iloc[0]:\n        poss_id = 'nflId_right'\n        poss_name = 'displayName_right'\n        def_id = 'nflId_left'\n        def_name = 'displayName_left'\n    elif poss_team == df.club_left.iloc[0]:\n        poss_id = 'nflId_left'\n        poss_name = 'displayName_left'\n        def_id = 'nflId_right'\n        def_name = 'displayName_right'\n    else:\n        raise ValueError(f'poss_team is invalid name. got {poss_team}')\n        \n    single_block_dict={}\n    double_block_dict={}\n    for f_id in df.sort_values(by=['frameId_left']).frameId_left.unique(): # left and right are the same value\n        df_1 = df[df.frameId_left==f_id].sort_values(by=[def_id])\n\n        for p_id in df_1[def_id].unique():   \n            \n            df_ = df_1[df_1[def_id]==p_id].reset_index().sort_values(by=[poss_id])\n\n            if len(df_)>2: # only want 1 rusher, 1-2 defenders\n                continue\n\n            # NOTE: dict usage not best practice but ok for now\n            if len(df_)==1:\n                key = (\n                    int(df_.iloc[0][def_id]),\n                    df_.iloc[0][def_name],\n                    int(df_.iloc[0][poss_id]),\n                    df_.iloc[0][poss_name],\n                )\n\n                if key in single_block_dict:\n                    single_block_dict[key].append(f_id) \n                else:\n                    single_block_dict[key] = [f_id]\n                continue\n\n            if len(df_)==2:\n                key = (\n                    int(df_.iloc[0][def_id]),\n                    df_.iloc[0][def_name],\n                    (\n                        int(df_.iloc[0][poss_id]),\n                        df_.iloc[0][poss_name],\n                        int(df_.iloc[1][poss_id]),\n                        df_.iloc[1][poss_name],\n                    )\n                )\n                if key in double_block_dict:\n                    double_block_dict[key].append(f_id) \n                else:\n                    double_block_dict[key] = [f_id]\n                continue\n    return single_block_dict, double_block_dict\n\ndef find_consecutive_groups(lst):\n    groups = []\n    start = lst[0] # start at 1st pos\n    end = lst[0] # ^ \n\n    for i in range(1, len(lst)):\n        if lst[i] <= end + 2: # if next value is < two more than current end\n            end = lst[i] # set end as the next value\n        else: # otherwise, we are end of conesecutive groups determine if worthy to add to list\n            if end != start: # if not length of one\n                groups.append([start, end]) # append to groups\n            start = lst[i] # reset to next value in loop\n            end = lst[i] # ^ \n\n    # for the last values (which wont hit else block)\n    if end != start:\n        groups.append([start, end])\n\n    return groups\n\ndef create_blocks_df(single_block_dict, double_block_dict):\n    records = []\n    for k,s in single_block_dict.items():\n        rusherId, rusherName, blocker1Id, blocker1Name = k\n        groups = find_consecutive_groups(list(s))\n        for group in groups:\n            records.append(\n                [group[0], group[1], rusherId, rusherName, blocker1Id, blocker1Name, None, None]\n            )\n    for k,d in double_block_dict.items():\n        rusherId, rusherName, blockers = k\n        blocker1Id, blocker1Name, blocker2Id, blocker2Name = blockers\n        groups = find_consecutive_groups(list(d))\n        for group in groups:\n            records.append(\n                [group[0], group[1], rusherId, rusherName, blocker1Id, blocker1Name, blocker2Id, blocker2Name]\n            )\n            \n    col_names = [\n        'frameIdStart',\n        'frameIdEnd', \n        'defenderId',\n        'defenderName',\n        'blocker1Id',\n        'blocker1Name',\n        'blocker2Id',\n        'blocker2Name'\n    ]\n    \n    return pd.DataFrame(records, columns=col_names)\n\ndef get_def_start_end_tracking_data(df:pd.DataFrame, p_track_df:pd.DataFrame):\n    df = df.merge(\n        p_track_df[['gameId', 'playId', 'nflId', 'frameId', 'playDirection', 'x', 'y', 's', 'a', 'dis', 'o', 'dir']],\n        how='left',\n        left_on=['gameId', 'playId', 'defenderId', 'frameIdStart'],\n        right_on=['gameId', 'playId', 'nflId', 'frameId'],\n        suffixes=('_left', '_right')\n    )\n    df = df.rename(columns={c:f'start_{c}' for c in ['x', 'y', 's', 'a', 'dis', 'o', 'dir']})\n    df = df.merge(\n        p_track_df[['gameId', 'playId', 'nflId', 'frameId', 'x', 'y']],\n        how='left',\n        left_on=['gameId', 'playId', 'defenderId', 'frameIdEnd'],\n        right_on=['gameId', 'playId', 'nflId', 'frameId'],\n        suffixes=('_left', '_right')\n    )\n    df = df.rename(columns={c:f'end_{c}' for c in ['x', 'y']})\n\n    drop_columns = [c for c in df if c.endswith('_left')] + [c for c in df if c.endswith('_right')]\n    # print(drop_columns)\n    return df.drop(drop_columns,axis=1)\n  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Data processing script\n\nimport pandas as pd\nimport polars as pl\n\nclass PlayerTracking:\n    def __init__(self):\n        self._game_table = self._get_game_table()\n\n    @staticmethod\n    def _get_game_table():\n        df_list = []\n        for i in range(1,10):\n            path = f'/kaggle/input/nfl-big-data-bowl-2025/tracking_week_{i}.csv'\n            df_list.append(\n                pl\n                .scan_csv(path)\n                .select('gameId')\n                .unique()\n                .with_columns(pl.lit(path).alias(\"path\"))\n            )\n        return pl.concat(df_list).collect().to_pandas()\n\n    @staticmethod\n    def _get_play_from_ids(path, g_id, p_id):\n        return (\n            pl\n            .scan_csv(path, ignore_errors=True)\n            .filter((pl.col('gameId')==g_id)&(pl.col('playId')==p_id)&(pl.col('frameType')!='BEFORE_SNAP'))\n            .collect()\n        )\n\n    def get_game(self, g_id) -> pl.DataFrame:\n        path = self._game_table[self._game_table.gameId==g_id]['path'].item()\n        return pl.read_csv(path, ignore_errors=True).filter((pl.col('gameId')==g_id))\n        \n    def get_play(self, p_id, g_ind:pl.DataFrame|int|None) -> pd.DataFrame:\n\n        if g_ind is None:\n            raise ValueError\n        # NOTE: not best practice...\n        if isinstance(g_ind, pl.DataFrame):\n            _play_filters = [\n                (pl.col('playId')==p_id), \n                (pl.col('frameType')!='BEFORE_SNAP')\n            ]\n            return g_ind.filter(_play_filters).to_pandas()\n            \n        if isinstance(g_ind, int):\n            path = self._game_table[self._game_table.gameId==g_ind]['path'].item()\n            _play_filters = [\n                (pl.col('gameId')==g_ind), \n                (pl.col('playId')==p_id), \n                (pl.col('frameType')!='BEFORE_SNAP')\n            ]\n            return pl.scan_csv(path, ignore_errors=True).filter(_play_filters).to_pandas()\n\ndef get_run_plays_dict(df, weeks:list|int|None=None):\n    if weeks:\n        if isinstance(weeks, int):\n            weeks = [weeks]\n        df = df[df.week.isin(weeks)]\n        \n    run_plays_tups = list(zip(df.gameId, df.playId))\n\n    d = {}\n    for tup in run_plays_tups:\n        gid, pid = tup\n        if gid in d:\n            d[gid].append(pid)\n        else:\n            d[gid]=[pid]\n    return d\n\n\ndef get_possession_team(df:pd.DataFrame, gid, pid):\n    return df[(df['gameId']==gid)&(df['playId']==pid)]['possessionTeam'].iloc[0]\n\ndef get_play_end(df):\n    play_end_events = ['out_of_bounds', 'tackle', 'fumble', 'fumble_offense_recovered', 'touchdown']\n    df_ = df[df.event.isin(play_end_events)].fillna(0).copy()\n    frame = list(df_.frameId)[0] if len(df_)>0 else df.frameId.max()\n    return df[df.frameId<=frame]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%time\n# PT = PlayerTracking()\n\n# for i in range(1,10):\n#     run_plays_dict = get_run_plays_dict(rush_df, weeks=[i])\n#     df_list = []\n#     for gid, pids in run_plays_dict.items():\n        \n#         game_df = PT.get_game(gid)\n\n#         for pid in pids:\n#             # print(gid, pid)\n#             _p_track_df = get_play_end(PT.get_play(pid, game_df))\n\n#             poss_team = get_possession_team(rush_df, gid, pid)\n\n#             _engaged_df = players_engaged_df(_p_track_df, .75, poss_team)\n#             if len(_engaged_df) == 0:\n#                 continue\n    \n#             single_block_dict, double_block_dict = get_blocks_from_engaged_df(_engaged_df, poss_team)\n            \n#             _blocks_df = create_blocks_df(single_block_dict, double_block_dict)\n#             _blocks_df['gameId'] = gid\n#             _blocks_df['playId'] = pid\n        \n#             _blocks_df = get_def_start_end_tracking_data(_blocks_df, _p_track_df)\n    \n#             df_list.append(_blocks_df)\n            \n#     df = pd.concat(df_list)\n\n#     ### NOTE: upon upload will consider this 'player engagement'\n#         # forgot to account for tackles.. will adjust data after loading \n#     df.to_parquet(f'/kaggle/working/blocks_week_{i}.parquet')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time \n# if player on right/left side of football\ndef get_player_side(row):\n    if row['fbStart_y']-2 < row['y'] < row['fbStart_y']+2:\n        return 'center'\n        \n    if row['playDirection'] == 'left':\n        if row['y'] > row['fbStart_y']:\n            return 'right'\n        else:\n            return 'left'\n    elif row['playDirection'] == 'right':\n        if row['y'] > row['fbStart_y']:\n            return 'left'\n        else:\n            return 'right'\n    else:\n        raise ValueError('bad playDirection')\n\ndef get_player_on_los(row):\n    if row['fbStart_x']+2 >= row['x'] >= row['fbStart_x']-2:\n        return 1\n    else:\n        return 0\n\ndef get_player_in_box(row):\n    if row['fbStart_y']+3.5 >= row['y'] >= row['fbStart_y']-3.5: # width = 3.5 yards (should make this more flexible/dynamic)\n        if row['fbStart_x']+5.5 >= row['x'] >= row['fbStart_x']-5.5: # depth = 5.5 yards\n            return 1\n    else:\n        return 0\n\ndef get_lineman(row):\n    if row['playerStartLOS'] == 1 and row['playerStartBox'] == 1:\n        return 1\n    else:\n        return 0\n\n# ball_df_list = []\n# player_df_list = []\n# for i in range(1, 10):\n#     p_track_df = pd.read_csv(f'/kaggle/input/nfl-big-data-bowl-2025/tracking_week_{i}.csv')\n\n#     # create football location df \n#     _football_loc_df = (\n#         p_track_df[\n#         (p_track_df.frameType!='BEFORE_SNAP')&\n#         (p_track_df.displayName=='football')\n#         ][['gameId', 'playId', 'frameId', 'frameType', 'x', 'y']]\n#     )\n\n#     _player_loc_df = (\n#         rush_df[rush_df.week==int(i)][['gameId', 'playId', 'week', 'possessionTeam']]\n#         .merge(\n#             (\n#                 p_track_df[\n#                 (p_track_df.frameType=='SNAP')&\n#                 (p_track_df.displayName!='football')]\n#                 .drop(['frameId', 'frameType'],axis=1) # to avoid dup when merging w fb_loc\n#             ), # players location at the snap\n#             how='left',\n#             on=['gameId', 'playId'])\n#         .merge(\n#             (\n#                 _football_loc_df[_football_loc_df.frameType=='SNAP']\n#                 .rename(columns={'x':'fbStart_x', 'y':'fbStart_y'})\n#             ),\n#             how='left',\n#             on=['gameId', 'playId'])\n#         .query('possessionTeam != club')\n#     )\n    \n#     # add dfs to list for concat later\n#     ball_df_list.append(_football_loc_df)\n#     player_df_list.append(_player_loc_df)\n    \n# player_loc_df = pd.concat(player_df_list)\n# ball_loc_df = pd.concat(ball_df_list)\n# ball_snap_df = ball_loc_df[ball_loc_df.frameType=='SNAP'] # used in the past but might not need anymore (probably?)\n\n# add the player positioning to df\n# player_loc_df['playerStartSide'] = player_loc_df.apply(get_player_side, axis=1)\n# player_loc_df['playerStartLOS'] = player_loc_df.apply(get_player_on_los, axis=1)\n# player_loc_df['playerStartBox'] = player_loc_df.apply(get_player_in_box, axis=1)\n# player_loc_df['playerStartLineman'] = player_loc_df.apply(get_lineman, axis=1)\n\n# ball_loc_df.to_parquet('/kaggle/working/ball_position.parquet')\n# player_loc_df.to_parquet('/kaggle/working/player_position.parquet')\n\nball_loc_df = pd.read_parquet('/kaggle/input/nfl-2022-position-tracking/ball_position.parquet')\nplayer_loc_df = pd.read_parquet('/kaggle/input/nfl-2022-position-tracking/player_position.parquet')\n\nplayer_loc_df['playerStartSide'] = player_loc_df.apply(get_player_side, axis=1)\nplayer_loc_df['playerStartLOS'] = player_loc_df.apply(get_player_on_los, axis=1)\nplayer_loc_df['playerStartBox'] = player_loc_df.apply(get_player_in_box, axis=1)\nplayer_loc_df['playerStartLineman'] = player_loc_df.apply(get_lineman, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n\n# Define the function\ndef get_backward_distance(row):\n    # Extract data from the row\n    start_x = row['start_x']\n    start_y = row['start_y']\n    start_o = row['start_o']\n    end_x = row['end_x']\n    end_y = row['end_y']\n    \n    # Convert angle to radians\n    theta = np.radians(start_o)\n    \n    # Calculate displacement\n    dx = end_x - start_x\n    dy = end_y - start_y\n    \n    # Calculate backward distance using the backward unit vector\n    backward_distance = dx * (-np.sin(theta)) + dy * (-np.cos(theta))\n    # backward_distance = dx * ((-np.sin(theta)) + dy * (-np.cos(theta)))\n    \n    return backward_distance\n\ndef get_distance(c1, c2):\n    return np.sqrt(\n        (c1[0]-c2[0])**2 + (c1[1]-c2[1])**2\n    )\n\nblocks_df = pd.read_parquet('/kaggle/input/nfl-2022-blocks-v2')\n\n# calculate the backward distance of defender for each block\nblocks_df['blockYardsCeded'] = blocks_df.apply(get_backward_distance, axis=1)\n\n# calculate the length of the block (may not be used?)\nblocks_df['blockLength'] = blocks_df['frameIdEnd'] - blocks_df['frameIdStart']\n\n# merge blocks with ball location\nblocks_df = blocks_df.merge(\n    (\n        ball_loc_df[['gameId', 'playId', 'frameId','x','y']]\n        .rename(columns={'x':'fbLoc_x', 'y':'fbLoc_y'})\n    ),\n    how='left',\n    left_on=['gameId', 'playId','frameIdStart'],\n    right_on=['gameId', 'playId', 'frameId']\n)\n\n# calculate distance from the ball to the defender\nblocks_df['distFromBall'] = blocks_df.apply(lambda x: get_distance((x['start_x'],x['start_y']),(x['fbLoc_x'],x['fbLoc_y'])), axis=1)\n\n# going to assume that any 'block' with .75 yds from ball is a tackle attempt\nblocks_df = blocks_df[blocks_df.distFromBall > .75]\n\nprint(blocks_df.shape)\ndisplay(blocks_df.head(2))\ndisplay(blocks_df.tail(2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"players_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/players.csv')\n\npos_groups_map = {\n    'DE':'DL',\n    'NT':'DL',\n    'SS':'DB',\n    'FS':'DB',\n    'OLB':'LB',\n    'DT':'DL',\n    'CB':'DB',\n    'ILB':'LB',\n    'MLB':'LB',\n    'DB':'DB',\n    'LB':'LB'\n}\n\nplayers_df['positionGroup'] = players_df['position'].map(pos_groups_map)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# only want to create metric on 7 weeks of data to ensure no data leakage\nblocks_df_wk_1_7 = (\n    games_df[games_df.week<=7][['gameId']]\n    .merge(blocks_df, how='left')\n)\n\nplayer_snap_df = (\n    blocks_df_wk_1_7[['defenderId', 'defenderName', 'playId']]\n    .drop_duplicates()\n    .groupby(['defenderId', 'defenderName'])[['playId']]\n    .agg(n_snaps=('playId', 'count'))\n    .reset_index()\n)\n\ns_block_df = (\n    blocks_df_wk_1_7[blocks_df_wk_1_7.blocker2Id.isna()]\n    .groupby(['defenderId' ,'defenderName'])[['blockYardsCeded', 'blockLength']]\n    .agg(\n        s_block_yc = ('blockYardsCeded', 'sum'),\n        s_block_length = ('blockLength', 'sum'),\n        s_block_count = ('blockLength', 'count')\n    )\n    .reset_index()\n)\nd_block_df = (\n    blocks_df_wk_1_7[~blocks_df_wk_1_7.blocker2Id.isna()]\n    .assign(d_block_yca=lambda x: -np.log(1 + (np.e ** (1-x['blockYardsCeded']))))\n    .groupby(['defenderId' ,'defenderName'])[['blockYardsCeded', 'd_block_yca', 'blockLength']]\n    .agg(\n        d_block_yc = ('blockYardsCeded', 'sum'),\n        d_block_yca = ('d_block_yca', 'sum'),\n        d_block_length = ('blockLength', 'sum'),\n        d_block_count = ('blockLength', 'count'),\n    )\n    .reset_index()\n)\n\nplayer_sd_blocks_df = (\n    s_block_df\n    .merge(d_block_df, on=['defenderId', 'defenderName'], how='left')\n    .merge(player_snap_df, how='left')\n    .merge(\n        players_df[['nflId', 'position', 'positionGroup']],\n        how='left',\n        left_on=['defenderId'],\n        right_on=['nflId'],\n    )\n)\n\nplayer_sd_blocks_df['%_time_d_blocked'] = player_sd_blocks_df['d_block_length'] / (player_sd_blocks_df['s_block_length'] + player_sd_blocks_df['d_block_length'])\nplayer_sd_blocks_df['n_blocks'] = player_sd_blocks_df['s_block_count'] + player_sd_blocks_df['d_block_count']\n\n# 0 -> S + D\n# 1 -> (S + D) / Nb\n# 2 -> (S + D) / Ns\n# 3 -> S + Da\n# 4 -> (S + Da) / Nb\n# 5 -> (S + Da) / Ns\n# 6 -> Sw + Dw\n# 7 -> (Sw + Dw) / Nb\n# 8-> (Sw + Dw) / Ns\n# 9 -> S / Nbs + D / Nbd\n\n# player_sd_blocks_df['yca0'] = player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yc']\n\n# player_sd_blocks_df['yca1'] = (player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yc']) / player_sd_blocks_df['n_blocks']\n\n# player_sd_blocks_df['yca2'] = (player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yc']) / player_sd_blocks_df['n_snaps']\n\n# player_sd_blocks_df['yca3'] = player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yca']\n\n# player_sd_blocks_df['yca4'] = (player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yca']) / player_sd_blocks_df['n_blocks']\n\n# player_sd_blocks_df['yca5'] = (player_sd_blocks_df['s_block_yc'] + player_sd_blocks_df['d_block_yca']) / player_sd_blocks_df['n_snaps']\n\nplayer_sd_blocks_df['yca6'] = (\n    (player_sd_blocks_df['s_block_yc'] * (1-player_sd_blocks_df['%_time_d_blocked'])+ \n     player_sd_blocks_df['d_block_yca'] * player_sd_blocks_df['%_time_d_blocked'] )\n)\n\n# player_sd_blocks_df['yca7'] = (\n#     (player_sd_blocks_df['s_block_yc'] * (1-player_sd_blocks_df['%_time_d_blocked'])+ \n#      player_sd_blocks_df['d_block_yca'] * player_sd_blocks_df['%_time_d_blocked'] ) / \n#     player_sd_blocks_df['n_blocks']\n# )\n\n# player_sd_blocks_df['yca8'] = (\n#     (player_sd_blocks_df['s_block_yc'] * (1-player_sd_blocks_df['%_time_d_blocked'])+ \n#      player_sd_blocks_df['d_block_yca'] * player_sd_blocks_df['%_time_d_blocked'] ) / \n#     player_sd_blocks_df['n_snaps']\n# )\n\n# player_sd_blocks_df['yca9'] = (\n#     (player_sd_blocks_df['s_block_yc'] / player_sd_blocks_df['s_block_count']) + (player_sd_blocks_df['d_block_yca'] / player_sd_blocks_df['d_block_count'])\n# )\n\nplayer_sd_blocks_df.head(2)\n\nmin_blocks = 30","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# MD 'Show' backwards distance diagram","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\n# tmp_df = player_metric_df.merge(player_sd_blocks_df).groupby('metric')[['%_time_d_blocked']].mean().reset_index()\n# plt.plot(tmp_df['metric'], tmp_df['%_time_d_blocked'], marker='o')\n_tmp_df = player_sd_blocks_df[player_sd_blocks_df.n_blocks>=min_blocks]\n_tmp_df['t_block_yc'] = (_tmp_df.s_block_yc + _tmp_df.d_block_yc) / _tmp_df.n_snaps\n    \n# trend line\nz = np.polyfit(_tmp_df.t_block_yc, _tmp_df['%_time_d_blocked'], 1)\np = np.poly1d(z)\n_tmp_df['trendline'] = p(_tmp_df.t_block_yc)\n    \nfig = px.scatter(\n    _tmp_df, \n    x='t_block_yc', \n    y='%_time_d_blocked', \n    hover_name='defenderName',\n    title='Average Defender Block Dislocation by Double Team Blocked %',\n    labels={\n        't_block_yc': 'Defender Block Dislocation',\n        '%_time_d_blocked': 'Double Teamed %'\n    }\n)\n    \n# trendline\nfig.add_scatter(\n    x=_tmp_df.t_block_yc, \n    y=_tmp_df['trendline'], \n    mode='lines', \n    name=f'Trend Line', \n    line=dict(dash='dash', color='red')\n)\n    \n# Customize legend and layout\nfig.update_traces(marker=dict(opacity=0.8, line=dict(width=1, color='black')))\nfig.update_layout(showlegend=False)\nfig.show()\n\n# fig.write_image(\"/kaggle/working/Ex3_AvgBD_by_PctDoubleTeamd.png\")\n# fig.write_html(\"/kaggle/working/Ex3_AvgBD_by_PctDoubleTeamd.html\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"var = 'yca6'\n\ndisplay(player_sd_blocks_df[player_sd_blocks_df.n_blocks>=min_blocks][var].describe())\nplayer_sd_blocks_df[player_sd_blocks_df.n_blocks>=min_blocks][var].min(), player_sd_blocks_df[player_sd_blocks_df.n_blocks>=min_blocks][var].max()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = (\n    player_sd_blocks_df[player_sd_blocks_df.n_blocks>=min_blocks]\n    .sort_values(by=var)[['defenderName', 'positionGroup', 's_block_yc', 'd_block_yca', var]]\n)\ntest.head(50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric = 'metric'\n_tmp_df = player_sd_blocks_df[player_sd_blocks_df.n_blocks>=30]\n_tmp_df[metric] = pd.qcut(_tmp_df[var], q=12, labels=False)+1\nplayer_metric_df = (\n    player_sd_blocks_df[['nflId' ,'defenderName', 'positionGroup', 'n_blocks']]\n    .drop_duplicates()\n    .merge(_tmp_df[['nflId', 'defenderName', var, metric]], how='left')\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"graph_index_df = player_metric_df[player_metric_df.n_blocks>min_blocks]\ngraph_index_df['metric'] = graph_index_df['metric'].astype('O')\nfig = px.bar(\n    graph_index_df,\n    x=\"metric\",\n    color=\"positionGroup\",\n    title=\"Block Dislocation Index by Position Group\",\n    labels={\"count\": \"Count\", \"metric\": \"Index\"},\n    hover_name='defenderName',\n    barmode=\"stack\"\n)\n# fig.write_html(\"/kaggle/working/Ex4_BD_by_PosGrp.html\")\n# fig.write_image(\"/kaggle/working/Ex4_BD_by_PosGrp.png\")\n\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(rush_df.shape)\ndisplay(rush_df.head(2))\n\nprint(player_loc_df.shape)\ndisplay(player_loc_df.head(2))\n\nprint(player_metric_df.shape)\ndisplay(player_metric_df.head(2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_playside_ind(row):\n    rush_typ = row['rushLocationType'].split('_')[0]\n    rush_dir = row['rushLocationType'].split('_')[-1].lower()\n    if row['playerStartSide'] == rush_dir:\n        return 1\n    if rush_typ=='INSIDE':\n        if row['playerStartSide'] == 'center':\n            return 1\n    return 0\n    # return 1 if row['playerStartSide'] == row['rushLocationType'].split('_')[-1].lower() else 0\n\ndef get_counter(row, lower, upper, metric):\n    ''' arbitarily setting the 'counter' (yes reference to blackjack counting) '''\n    if row[metric] > upper:\n        return 1\n    elif row[metric] < lower:\n        return -1\n    else:\n        return 0\n\n\nloc_drop_cols = [\n    'week', \n    'possessionTeam', \n    'displayName', \n    'time', \n    'jerseyNumber',\n    'x',\n    'y',\n    's', \n    'a',\n    'dis',\n    'o',\n    'dir',\n    'event',\n    'frameId',\n    'frameType'\n]\nbase_df = (\n    rush_df\n    .merge(\n        (\n            player_loc_df\n            .drop(loc_drop_cols, axis=1)\n        ),\n        how='left',\n        on=['gameId', 'playId']\n    )\n    .merge(\n        (\n            player_metric_df\n            # .drop(['nflId'], axis=1)\n        ),\n        how='left',\n        # left_on='nflId',\n        # right_on='defenderId'\n    )\n)\n\nbase_df['playerStartRushLocationSide'] = base_df.apply(get_playside_ind, axis=1) # great name\n\n# arbitarily setting the count\nmetric_count = f'{metric}_count'\n# base_df[metric_count] = base_df.apply(get_counter, args=(2, 8, metric), axis=1)\nbase_df[metric_count] = base_df['metric'].map({\n    1:0,\n    2:0,\n    3:1,\n    4:1,\n    5:1,\n    6:1,\n    7:2,\n    8:2,\n    9:2,\n    10:2,\n    11:2,\n    12:2,\n})\n\nplay_pos_grp_df = (\n    base_df\n    .groupby(['gameId', 'playId', 'positionGroup'])\n    .size()\n    .reset_index(name='count')\n    .pivot(index=['gameId', 'playId'], columns='positionGroup', values='count')\n    .reset_index()\n)\n\n# print(base_df.shape)\n# base_df.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## this is ugly... surely theres a better way.....\n\nbase_df[f'{metric}_allPlayerAvg'] = base_df.groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_boxPlayerAvg'] = base_df[base_df.playerStartBox==1].groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_losPlayerAvg'] = base_df[base_df.playerStartLOS==1].groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_linemanPlayerAvg'] = base_df[base_df.playerStartLineman==1].groupby(['gameId', 'playId'])[metric].transform('mean')\n\nbase_df[f'{metric}_allPlayerCnt'] = base_df.groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_boxPlayerCnt'] = base_df[base_df.playerStartBox==1].groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_losPlayerCnt'] = base_df[base_df.playerStartLOS==1].groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_linemanPlayerCnt'] = base_df[base_df.playerStartLineman==1].groupby(['gameId', 'playId'])[metric_count].transform('sum')\n\nbase_df[f'{metric}_allPlaysidePlayerAvg'] = base_df[base_df.playerStartRushLocationSide==1].groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_boxPlaysidePlayerAvg'] = base_df[(base_df.playerStartBox==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_losPlaysidePlayerAvg'] = base_df[(base_df.playerStartLOS==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric].transform('mean')\nbase_df[f'{metric}_linemanPlaysidePlayerAvg'] = base_df[(base_df.playerStartLineman==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric].transform('mean')\n\nbase_df[f'{metric}_allPlaysidePlayerCnt'] = base_df[base_df.playerStartRushLocationSide==1].groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_boxPlaysidePlayerCnt'] = base_df[(base_df.playerStartBox==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_losPlaysidePlayerCnt'] = base_df[(base_df.playerStartLOS==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric_count].transform('sum')\nbase_df[f'{metric}_linemanPlaysidePlayerCnt'] = base_df[(base_df.playerStartLineman==1)&(base_df.playerStartRushLocationSide==1)].groupby(['gameId', 'playId'])[metric_count].transform('sum')\n\ngrp_cols = ['gameId', 'playId']\nfirst_cols = [\n    'quarter',\n    'down',\n    'week',\n    'possessionTeam',\n    'yardsToGo',\n    'rushLocationType',\n    'yardsGained',\n    'pff_runConceptPrimary',\n    'pff_runConceptSecondary',\n    'runSuccess'\n]\navg_cols = list(base_df.columns[-16:])\n\nagg_dict = {**{c:'first' for c in first_cols}, **{c:'mean' for c in avg_cols}}\n\npsp_df = base_df.groupby(grp_cols).agg(agg_dict).reset_index().merge(play_pos_grp_df, how='left')\n\n# all_m = [c for c in psp_df if c.startswith('metric')]\n# psp_df[all_m + ['DB', 'DL', 'LB']] = psp_df[all_m+ ['DB', 'DL', 'LB']].fillna(0)\n\npsp_df.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_track_play(df, gid, pid):\n    return df[(df['gameId']==gid)&(df['playId']==pid)]\n\ndef animate_play(df, yards_to_go):\n\n    # Determine the line of scrimmage\n    line_of_scrimmage = list(df[(df.displayName=='football')&(df.frameId==1)]['x'])[0]\n    line_first_down = round(abs(line_of_scrimmage - yards_to_go)) if df['playDirection'].iloc[0] == 'left' else round(abs(line_of_scrimmage + yards_to_go))\n\n    snap_id = list(df[df.frameType=='SNAP']['frameId'])[0]\n    df=df[df.frameId>snap_id-20]\n    \n    # Define the field dimensions\n    min_x = max(0, df[\"x\"].min() - 10)\n    max_x = df[\"x\"].max() + 10\n    field_height = [0, 53.3]\n    \n    fig = px.scatter(\n        df,\n        x=\"x\",\n        y=\"y\",\n        color=\"club\",\n        hover_name=\"displayName\",\n        animation_frame=\"frameId\",\n        text=\"jerseyNumber\", \n        # size_max=50 # not working\n    )\n\n    # fig.update_traces(marker=dict(size=10))\n\n    # Style the text on the markers\n    fig.update_traces(\n        marker=dict(size=15),\n        textfont=dict(size=12, color=\"white\"),  # Adjust text size and color\n        textposition=\"middle center\",  # Position text in the center of each marker\n    )\n    \n    # Add a green background for the field\n    fig.update_layout(\n        plot_bgcolor=\"green\",\n        xaxis=dict(range=[min_x, max_x], title=\"Yards\", zeroline=False, showgrid=False),\n        # xaxis=dict(range=[10, 110], title=\"Yards\", zeroline=False, showgrid=False),\n        yaxis=dict(range=field_height, title=\"Yards\", zeroline=False, showgrid=False),\n    )\n\n    # Add the line of scrimmage (blue) and first down line (yellow)\n    fig.add_shape(\n        type=\"line\",\n        x0=line_of_scrimmage,\n        x1=line_of_scrimmage,\n        y0=field_height[0],\n        y1=field_height[1],\n        line=dict(color=\"blue\", width=2),\n        name=\"Line of Scrimmage\"\n    )\n    fig.add_shape(\n        type=\"line\",\n        x0=line_first_down,\n        x1=line_first_down,\n        y0=field_height[0],\n        y1=field_height[1],\n        line=dict(color=\"yellow\", width=2),\n        name=\"First Down\"\n    )\n\n    # yard to go -- not working\n    # fig.add_annotation(\n    #     x=(line_of_scrimmage + line_first_down) / 2,\n    #     y=field_height[1] + 1,\n    #     text=f\"Yards to Gain: {yards_to_go}\",\n    #     showarrow=True,\n    #     font=dict(color=\"black\", size=16),\n    #     # bgcolor=\"rgba(0,0,0,0.7)\",\n    #     # borderpad=5,\n    # )\n\n    # Add yard lines (10-yard increments)\n    for x in range(int(min_x), int(max_x) + 1, 10):\n    # for x in range(10, 110 + 1, 10):\n        fig.add_shape(\n            type=\"line\",\n            x0=x,\n            x1=x,\n            y0=field_height[0],\n            y1=field_height[1],\n            line=dict(color=\"white\", width=1, dash=\"dot\"),\n        )\n    \n    fig.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 150\n    \n    return fig\np_track_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2025/tracking_week_1.csv')\nplay_df = get_track_play(p_track_df, 2022091100, 2353)\n\n# animate_play(play_df, 10)#.write_html(\"/kaggle/working/play_animation_2022091100_2353.html\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"play_df.head(2)\nbase_df.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_count(df, yards_to_go):\n    line_of_scrimmage = list(df[df.displayName=='football']['x'])[0]\n    line_first_down = round(abs(line_of_scrimmage - yards_to_go)) if df['playDirection'].iloc[0] == 'left' else round(abs(line_of_scrimmage + yards_to_go))\n    \n    # Define the field dimensions\n    min_x = max(0, df[\"x\"].min() - 10)\n    max_x = df[\"x\"].max() + 10\n    field_height = [0, 53.3]\n    \n    fig = px.scatter(\n        df,\n        x=\"x\",\n        y=\"y\",\n        color=\"playerStartSide\",\n        hover_name=\"displayName\",\n        text=\"metric\"\n    )\n    \n    # Style the text on the markers\n    fig.update_traces(\n        marker=dict(size=15),\n        textfont=dict(size=12, color=\"white\"),  # Adjust text size and color\n        textposition=\"middle center\",  # Position text in the center of each marker\n    )\n    \n    # Add a green background for the field\n    fig.update_layout(\n        plot_bgcolor=\"green\",\n        xaxis=dict(range=[min_x, max_x], title=\"Yards\", zeroline=False, showgrid=False),\n        # xaxis=dict(range=[10, 110], title=\"Yards\", zeroline=False, showgrid=False),\n        yaxis=dict(range=field_height, title=\"Yards\", zeroline=False, showgrid=False),\n    )\n\n    # Add the line of scrimmage (blue) and first down line (yellow)\n    fig.add_shape(\n        type=\"line\",\n        x0=line_of_scrimmage,\n        x1=line_of_scrimmage,\n        y0=field_height[0],\n        y1=field_height[1],\n        line=dict(color=\"blue\", width=2),\n        name=\"Line of Scrimmage\"\n    )\n    fig.add_shape(\n        type=\"line\",\n        x0=line_first_down,\n        x1=line_first_down,\n        y0=field_height[0],\n        y1=field_height[1],\n        line=dict(color=\"yellow\", width=2),\n        name=\"First Down\"\n    )\n\n    for x in range(round(int(min_x), -1), round(int(max_x) + 1, -1), 10):\n    # for x in range(10, 110 + 1, 10):\n        fig.add_shape(\n            type=\"line\",\n            x0=x,\n            x1=x,\n            y0=field_height[0],\n            y1=field_height[1],\n            line=dict(color=\"white\", width=1, dash=\"dot\"),\n        )\n\n    football_x = list(df[df.displayName == 'football']['x'])[0]\n    football_y = list(df[df.displayName == 'football']['y'])[0]\n\n    # Define the bounds of the dotted box\n    box_x_min = football_x\n    box_x_max = football_x + 5.5\n    box_y_min = football_y - 3.5\n    box_y_max = football_y + 3.5\n\n    # Add the dotted box to the plot\n    fig.add_shape(\n        type=\"rect\",\n        x0=box_x_min,\n        x1=box_x_max,\n        y0=box_y_min,\n        y1=box_y_max,\n        line=dict(color=\"red\", width=2, dash=\"dot\"),\n    )\n    \n    return fig\n\n#list(play_df[play_df.frameType=='SNAP'].frameId)[0]-1 # -1\ntmp_df = play_df[play_df.frameId==151].merge(base_df, how='left')[['displayName', 'club', 'jerseyNumber', 'playDirection', 'x', 'y','playerStartSide', 'metric']]\ntmp_df['metric'] = tmp_df['metric'].map({\n    1:0,\n    2:0,\n    3:1,\n    4:1,\n    5:1,\n    6:1,\n    7:2,\n    8:2,\n    9:2,\n    10:2,\n    11:2,\n    12:2,\n})\ntmp_df['playerStartSide'] = tmp_df['playerStartSide'].fillna('offense')\ntmp_df.loc[22, 'playerStartSide'] = 'football'\ntmp_df['metric'] = tmp_df['metric'].fillna(99).astype(int).astype('O').replace(99,'')\nfig = show_count(tmp_df, 10)\n# tmp_df\n# fig.write_html(f\"/kaggle/working/Ex9_BDIC_presnap.html\")\n# fig.write_image(f\"/kaggle/working/Ex9_BDIC_presnap.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# psp_df[psp_df.columns[-16:]].describe()\npsp_df[['runSuccess']+[c for c in psp_df if c.startswith('metric')]].corr()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Exhibit 5 -- Show pattern of avoiding the top players on DL and in box is beneficial\n\ndef get_run_success_matrix(var):\n    df_list = []\n    for ds in ['train', 'holdout']:\n        filter_ = (~psp_df.week.isin([8,9])) if ds=='train' else (psp_df.week.isin([8,9]))\n        tmp_df = (\n            psp_df[filter_]\n            .groupby(var)[['runSuccess']]\n            .agg(\n                count=('runSuccess', 'count'), \n                avg_success=('runSuccess', 'mean')\n            )\n            .reset_index()\n            .rename(columns={'count':f'{ds}_count', 'avg_success':f'{ds}_avg_success'})\n        )\n        df_list.append(tmp_df)\n    df = df_list[0].merge(df_list[1], on=var)\n    return df\n# display(get_run_success_matrix('metric_linemanPlaysidePlayerCnt'))\ndisplay(get_run_success_matrix('metric_boxPlaysidePlayerCnt'))\n\npsp_df['count_range'] = np.where(psp_df['metric_boxPlaysidePlayerCnt'] < 2, '0-2', '3+')\npsp_df['partition'] = np.where(psp_df['week'] <8, 'training', 'testing')\ngrp_df = psp_df.groupby(['count_range', 'partition'])['runSuccess'].mean().unstack()\ngrp_df.reset_index()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\n\ndef get_run_success_matrix(var, psp_df, max_=6):\n    title = 'Run Success by Play BDI Count'\n\n    # Split data into train and test sets\n    filter_train = (~psp_df.week.isin([8, 9]))\n    filter_test = (psp_df.week.isin([8, 9]))\n\n    # Calculate standard error for each group\n    tmp_df_train = (\n        psp_df[filter_train]\n        .groupby(var)[['runSuccess']]\n        .agg(\n            count=('runSuccess', 'count'),\n            avg_success=('runSuccess', 'mean'),\n            std_error=('runSuccess', lambda x: np.std(x) / np.sqrt(len(x)))  # Standard error\n        )\n        .reset_index()\n    )\n    tmp_df_test = (\n        psp_df[filter_test]\n        .groupby(var)[['runSuccess']]\n        .agg(\n            count=('runSuccess', 'count'),\n            avg_success=('runSuccess', 'mean'),\n            std_error=('runSuccess', lambda x: np.std(x) / np.sqrt(len(x)))  # Standard error\n        )\n        .reset_index()\n    )\n\n    # Filter by the max_ value\n    tmp_df_train = tmp_df_train[tmp_df_train[var] <= max_]\n    tmp_df_test = tmp_df_test[tmp_df_test[var] <= max_]\n\n    # Create the figure\n    fig = go.Figure()\n\n    # Add mean + error bars for the training dataset\n    fig.add_trace(go.Scatter(\n        x=[x-.2 for x in tmp_df_train[var]],\n        y=tmp_df_train['avg_success'],\n        error_y=dict(\n            type='data',\n            array=tmp_df_train['std_error'],\n            visible=True\n        ),\n        mode='markers',\n        name='Train',\n        marker=dict(color='blue')\n    ))\n\n    # Add mean + error bars for the validation dataset\n    fig.add_trace(go.Scatter(\n        x=[x+.2 for x in tmp_df_test[var]],\n        y=tmp_df_test['avg_success'],\n        error_y=dict(\n            type='data',\n            array=tmp_df_test['std_error'],\n            visible=True\n        ),\n        mode='markers',\n        name='Test',\n        marker=dict(color='red')\n    ))\n\n    # Add count bars for the training dataset\n    fig.add_trace(go.Bar(\n        x=[x - 0.2 for x in tmp_df_train[var]],  # Shift bars slightly to the left\n        y=tmp_df_train['count'],\n        name='Train Count',\n        marker=dict(color='blue', opacity=0.3),\n        yaxis='y2',\n        showlegend=False\n    ))\n\n    # Add count bars for the validation dataset\n    fig.add_trace(go.Bar(\n        x=[x + 0.2 for x in tmp_df_test[var]],  # Shift bars slightly to the right\n        y=tmp_df_test['count'],\n        name='Test Count',\n        marker=dict(color='red', opacity=0.3),\n        yaxis='y2',\n        showlegend=False\n    ))\n\n    # Update layout for dual y-axes and legend\n    fig.update_layout(\n        title=title,\n        xaxis=dict(title='BDI Count in Box on Playside'),\n        yaxis=dict(title='Avg. Run Success', side='left'),\n        yaxis2=dict(\n            title='Plays',\n            overlaying='y',\n            side='right'\n        ),\n        barmode='group',  # Group bars side by side\n        legend=dict(title='Legend'),\n    )\n\n    return fig, title\nfig, title = get_run_success_matrix('metric_boxPlaysidePlayerCnt', psp_df)\nfig.show()\n# fig.write_html(f\"/kaggle/working/Ex5_{'_'.join(title.split(' '))}.html\")\n# fig.write_image(f\"/kaggle/working/Ex5_{'_'.join(title.split(' '))}.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.inspection import PartialDependenceDisplay\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\ndef pdp_feature(model, df, feature_name, feature_names):\n    if isinstance(feature_name, str):\n        feature_name = [feature_name]\n    features = [feature_names.index(f) for f in feature_name]\n    fig, ax = plt.subplots(figsize=(12, 6))\n    PartialDependenceDisplay.from_estimator(model, df, features, ax=ax)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def data_prep(drop_cols, m=True):\n    df = psp_df[psp_df.down.isin([1,2,3,4])].drop(['count_range', 'partition'], axis=1)\n    \n    all_m = [c for c in psp_df if c.startswith('metric')]\n    \n    if m:\n        df = df.drop([c for c in all_m if c!='metric_boxPlaysidePlayerCnt'], axis=1)\n    else:\n        df = df.drop(all_m, axis=1)\n    \n    label_encoder = LabelEncoder()\n    for cat_col in ['rushLocationType', 'possessionTeam', 'pff_runConceptPrimary', 'pff_runConceptSecondary']:\n        df[cat_col] = label_encoder.fit_transform(df[cat_col])\n    \n    train_df = df[df.week<=7]\n    test_df = df[df.week>7]\n \n    X_train = train_df[[c for c in df if c not in drop_cols]]\n    y_train = train_df['runSuccess']\n\n    X_test = test_df[[c for c in df if c not in drop_cols]]\n    y_test = test_df['runSuccess']\n\n    return X_train, X_test, y_test, y_train\n\n# print(y_train.mean())\n# print(y_test.mean())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop_cols = [\n#     'gameId',\n#     'playId',\n#     'week',\n#     'runSuccess',\n#     'yardsGained',\n#     'possessionTeam',\n#     'DB',\n#     'DL',\n#     'LB',\n#     'pff_runConceptPrimary',\n#     # 'pff_runConceptSecondary',\n#     ]\n\n# X_train, X_test, y_test, y_train = data_prep(drop_cols, True)\n\n# param_space = {\n#     'num_leaves': (4, 70),\n#     'max_depth': (3, 20),\n#     'learning_rate': (0.005, 0.3, 'log-uniform'),\n#     'n_estimators': (20, 200)\n# }\n\n# opt = BayesSearchCV(\n#     estimator=lgb.LGBMClassifier(),\n#     search_spaces=param_space,\n#     cv=StratifiedKFold(n_splits=5),\n#     n_iter=32,\n#     scoring='accuracy',\n#     n_jobs=-1,\n#     verbose=0\n# ).fit(X_train, y_train)\n\n# # Best parameters\n# print(opt.best_params_) # params\n# print( opt.best_score_) # score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"drop_cols = [\n    'gameId',\n    'playId',\n    'week',\n    'quarter',\n    'runSuccess',\n    'yardsGained',\n    'possessionTeam',\n    'DB',\n    'DL',\n    'LB',\n    # 'pff_runConceptPrimary',\n    'pff_runConceptSecondary',\n    ]\n\nX_train, X_test, y_test, y_train = data_prep(drop_cols, True)\n\nmodel_a_params = {\n    'learning_rate':0.01,\n    'max_depth':4,\n    'n_estimators':163,\n    'num_leaves':69,\n    'verbose':-1\n}\nmodel_a = lgb.LGBMClassifier(**model_a_params).fit(X_train, y_train)\n\ndisplay(dict(zip(model_a.feature_name_, model_a.feature_importances_)))\n\ny_pred = model_a.predict(X_test)\n# print(y_pred.mean())\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_test, y_train = data_prep(drop_cols, False)\n\nmodel_b_params = {\n    'learning_rate':0.0492,\n    'max_depth':4,\n    'n_estimators':34,\n    'num_leaves':47,\n    'verbose':-1\n}\nmodel_b = lgb.LGBMClassifier(**model_b_params).fit(X_train, y_train)\n\ndisplay(dict(zip(model_b.feature_name_, model_b.feature_importances_)))\n\ny_pred = model_b.predict(X_test)\n# print(y_pred.mean())\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pdp_feature(\n    model_a, \n    X_train, \n    'metric_boxPlaysidePlayerCnt', \n    model_a.feature_name_\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# param_space = {\n#     'max_iter': (50, 200),\n#     'max_leaf_nodes': (20, 50),\n#     'learning_rate': (0.01, 0.3, 'log-uniform'),\n#     'max_depth': (5, 15)\n# }\n\n# opt = BayesSearchCV(\n#     estimator=HistGradientBoostingClassifier(max_iter=200),\n#     search_spaces=param_space,\n#     cv=StratifiedKFold(n_splits=5),\n#     n_iter=32,\n#     scoring='accuracy',\n#     n_jobs=-1,\n#     verbose=0\n# ).fit(X_train, y_train)\n\n# # Best parameters\n# print(opt.best_params_) # params\n# print( opt.best_score_) # score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# hgbc_params = {\n#     'learning_rate':0.018487089636919054,\n#     'max_depth':8,\n#     'max_iter':158,\n#     'max_leaf_nodes':20,\n#     'verbose':0\n# }\n# model = HistGradientBoostingClassifier(**hgbc_params).fit(X_train, y_train)\n# # dict(zip(model.feature_names_in_, model.feature_importances_))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_pred = model.predict(X_test)\n# print(y_pred.mean())\n# print(f'Accuracy: {accuracy_score(y_test, y_pred)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pdp_feature(\n#     model, \n#     X_train, \n#     m, \n#     list(model.feature_names_in_)\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}